# StegaNet 测试版

---
尝试开始构建自己的模型，大概会是一个基于 Transformer 以及 CNN 的混合模型

## To Do

- [ ] 编写 U-Net 组成的编码器
- [ ] 数据增强技术
    - [ ] 随机裁切
    - [ ] 随机翻转
    - [x] 通道重排
    - [] mixup
- [ ] 寻找更合适的损失函数
    - [x] 使用 Charbonnier Loss
- [ ] 提高 GPU 利用率
- [ ] 训练策略
    - [ ] 添加学习率衰减
    - [ ] 不使用端到端训练，而是逐个模块进行训练
    - [ ] 预训练的方式

## V 0.1

### V0.1 架构概述

> 该架构参考 ViT-B，除了嵌入维度以及方式不同其余基本一致

1. 输入使用单层 CNN 提取特征
2. 12 层 ViT 处理
3. 单块 Transformer 重建
4. 该版本主要是把任务的 pipline 建立起来，之后好进行修改并进行模型的验证

### 输入输出

编码器

- 输入：两张 3 通道图像，按照通道级联变为 6 通道图像
- 输出：3 通道图像

解码器：

- 输入输出均为 3 通道图像

### 问题

1. 模型较小，输入的图像分辨率也较小
2. 由于有记录训练中间状态，所以 GPU 占用率一直不高
3. 解码器解码质量比编码器编码质量要好
4. 输入数据的组成有问题，不应该按照通道级联，这个是 CNN 的数据输入方式

## V0.2

### V0.2 架构概述

> 该输入有问题，Cover 图像会和自己计算自注意力，废弃

1. 使用 Transformer + CNN 双分支作为主体结构
2. 添加**判别器**
3. 不再使用 CNN 做特征提取，而是直接使用 MLP 做 embedding
4. 使用 U-Net 架构作为编码器，同样使用轻量化解码器和判别器

